{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to attempt tuning on the entire feature set first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X_train_dc = pd.read_pickle('../pickles/split/X_train_dc.pkl')\n",
    "y_train_dc = pd.read_pickle('../pickles/split/y_train_dc.pkl')\n",
    "\n",
    "X_train_l = pd.read_pickle('../pickles/split/X_train_l.pkl')\n",
    "y_train_l = pd.read_pickle('../pickles/split/y_train_l.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on initial performance, I'm going to be doing tuning for `RandomForestRegressor` and `XGBRegressor`, as they were the most effective, and I'm going to start with all of the features to see if one of the two models does significantly better than the other. If one is out performing the other, that will be the only one I tune on the sets with restricted features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error, r2_score, make_scorer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor(random_state=42)\n",
    "boost = XGBRegressor(objective='reg:squarederror',random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DC set**, all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_forest_dc = {\n",
    "    'n_estimators': [125,130,135,140,145,150,155],\n",
    "    'max_depth': [19,20,21]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.6895321510957303\n",
      "Best Hyperparameters: {'max_depth': 20, 'n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "search_forest_dc1 = GridSearchCV(forest, space_forest_dc, scoring='r2',n_jobs=-1)\n",
    "result_forest_dc1 = search_forest_dc1.fit(X_train_dc,y_train_dc)\n",
    "print('Best Score: %s' % result_forest_dc1.best_score_)\n",
    "print('Best Hyperparameters: %s' % result_forest_dc1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 71.84172119174976\n",
      "Best Hyperparameters: {'max_depth': 20, 'n_estimators': 130}\n"
     ]
    }
   ],
   "source": [
    "search_forest_dc2 = GridSearchCV(forest, space_forest_dc, scoring='neg_root_mean_squared_error',n_jobs=-1)\n",
    "result_forest_dc2 = search_forest_dc2.fit(X_train_dc,y_train_dc)\n",
    "print('Best Score: %s' % (result_forest_dc2.best_score_*-1))\n",
    "print('Best Hyperparameters: %s' % result_forest_dc2.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**London set**, all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_forest_l = {\n",
    "    'n_estimators': [180,185,190],\n",
    "    'max_depth': [19,20,21]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.9028084805222928\n",
      "Best Hyperparameters: {'max_depth': 20, 'n_estimators': 185}\n"
     ]
    }
   ],
   "source": [
    "search_forest_l1 = GridSearchCV(forest, space_forest_l, scoring='r2',n_jobs=-1)\n",
    "result_forest_l1 = search_forest_l1.fit(X_train_l,y_train_l)\n",
    "print('Best Score: %s' % result_forest_l1.best_score_)\n",
    "print('Best Hyperparameters: %s' % result_forest_l1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 312.8454875514148\n",
      "Best Hyperparameters: {'max_depth': 20, 'n_estimators': 185}\n"
     ]
    }
   ],
   "source": [
    "search_forest_l2 = GridSearchCV(forest, space_forest_l, scoring='neg_root_mean_squared_error',n_jobs=-1)\n",
    "result_forest_l2 = search_forest_l2.fit(X_train_l,y_train_l)\n",
    "print('Best Score: %s' % (result_forest_l2.best_score_*-1))\n",
    "print('Best Hyperparameters: %s' % result_forest_l2.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DC set**, all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_boost_dc1 = {\n",
    "    'alpha': [3,3.5,4],\n",
    "    'lambda': [90,100,110],\n",
    "    'max_depth': [7,8,9],\n",
    "    'learning_rate': [0.5,0.4,0.3],\n",
    "    'n_estimators': [65,70,75]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.7963137030601501\n",
      "Best Hyperparameters: {'alpha': 3.5, 'lambda': 100, 'learning_rate': 0.4, 'max_depth': 8, 'n_estimators': 70}\n"
     ]
    }
   ],
   "source": [
    "search_boost_dc1 = GridSearchCV(boost, space_boost_dc1, scoring='r2',n_jobs=-1)\n",
    "result_boost_dc1 = search_boost_dc1.fit(X_train_dc,y_train_dc)\n",
    "print('Best Score: %s' % result_boost_dc1.best_score_)\n",
    "print('Best Hyperparameters: %s' % result_boost_dc1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_boost_dc2 = {\n",
    "    'alpha': [0,0.1,0.01],\n",
    "    'lambda': [90,100,110],\n",
    "    'max_depth': [5,6,7],\n",
    "    'learning_rate': [0.4,0.3,0.2],\n",
    "    'n_estimators': [175,180,185]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 56.490411500995606\n",
      "Best Hyperparameters: {'alpha': 0.1, 'lambda': 100, 'learning_rate': 0.3, 'max_depth': 6, 'n_estimators': 180}\n"
     ]
    }
   ],
   "source": [
    "search_boost_dc2 = GridSearchCV(boost, space_boost_dc2, scoring='neg_root_mean_squared_error',n_jobs=-1)\n",
    "result_boost_dc2 = search_boost_dc2.fit(X_train_dc,y_train_dc)\n",
    "print('Best Score: %s' % (result_boost_dc2.best_score_*-1))\n",
    "print('Best Hyperparameters: %s' % result_boost_dc2.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**London set**, all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_boost_l1 = {\n",
    "    'alpha': [0.3,0.2,0.1],\n",
    "    'lambda': [100,110,120],\n",
    "    'max_depth': [5,6,7],\n",
    "    'learning_rate': [0.3,0.2,0.1],\n",
    "    'n_estimators': [120,130,140]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.919543719291687\n",
      "Best Hyperparameters: {'alpha': 0.2, 'lambda': 110, 'learning_rate': 0.2, 'max_depth': 6, 'n_estimators': 130}\n"
     ]
    }
   ],
   "source": [
    "search_boost_l1 = GridSearchCV(boost, space_boost_l1, scoring='r2',n_jobs=-1)\n",
    "result_boost_l1 = search_boost_l1.fit(X_train_l,y_train_l)\n",
    "print('Best Score: %s' % result_boost_l1.best_score_)\n",
    "print('Best Hyperparameters: %s' % result_boost_l1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_boost_l2 = {\n",
    "    'alpha': [1,0.75,0.5],\n",
    "    'lambda': [100,125,150],\n",
    "    'max_depth': [6,7,8],\n",
    "    'learning_rate': [0.4,0.3,0.2],\n",
    "    'n_estimators': [60,70,80]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 293.8955040541115\n",
      "Best Hyperparameters: {'alpha': 0.75, 'lambda': 125, 'learning_rate': 0.3, 'max_depth': 7, 'n_estimators': 70}\n"
     ]
    }
   ],
   "source": [
    "search_boost_l2 = GridSearchCV(boost, space_boost_l2, scoring='neg_root_mean_squared_error',n_jobs=-1)\n",
    "result_boost_l2 = search_boost_l2.fit(X_train_l,y_train_l)\n",
    "print('Best Score: %s' % (result_boost_l2.best_score_*-1))\n",
    "print('Best Hyperparameters: %s' % result_boost_l2.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to compare the models, both to each other and to the untuned model. (I am copying in the results from the prior notebook rather than running them again.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: \n",
      "DC set: \n",
      "Base model r2: 0.8908068409097215 \n",
      "Tuned model r2: 0.6895321510957303\n",
      "\n",
      "Base model rmse: 72.87654665983804 \n",
      "Tuned model rmse: 71.84172119174976\n",
      "\n",
      "London set: \n",
      "Base model r2: 0.9343686316506019 \n",
      "Tuned model r2: 0.9028084805222928\n",
      "\n",
      "Base model rmse: 289.163573168845 \n",
      "Tuned model rmse: 312.8454875514148\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest: \\nDC set: \\nBase model r2: 0.8908068409097215 \\nTuned model r2:',result_forest_dc1.best_score_)\n",
    "print('\\nBase model rmse: 72.87654665983804 \\nTuned model rmse:',(result_forest_dc2.best_score_*-1))\n",
    "print('\\nLondon set: \\nBase model r2: 0.9343686316506019 \\nTuned model r2:',result_forest_l1.best_score_)\n",
    "print('\\nBase model rmse: 289.163573168845 \\nTuned model rmse:',(result_forest_l2.best_score_*-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForest seems to perform worse after hyperparameter tuning, aside from a tiny improvement in the error score for the DC data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost: \n",
      "DC set: \n",
      "Base model r2: 0.8994784355163574 \n",
      "Tuned model r2: 0.7963137030601501\n",
      "\n",
      "Base model rmse: 69.92294989890084 \n",
      "Tuned model rmse: 56.490411500995606\n",
      "\n",
      "London set: \n",
      "Base model r2: 0.9133748412132263 \n",
      "Tuned model r2: 0.919543719291687\n",
      "\n",
      "Base model rmse: 332.20786503370334 \n",
      "Tuned model rmse: 293.8955040541115\n"
     ]
    }
   ],
   "source": [
    "print('XGBoost: \\nDC set: \\nBase model r2: 0.8994784355163574 \\nTuned model r2:',result_boost_dc1.best_score_)\n",
    "print('\\nBase model rmse: 69.92294989890084 \\nTuned model rmse:',(result_boost_dc2.best_score_*-1))\n",
    "print('\\nLondon set: \\nBase model r2: 0.9133748412132263 \\nTuned model r2:',result_boost_l1.best_score_)\n",
    "print('\\nBase model rmse: 332.20786503370334 \\nTuned model rmse:',(result_boost_l2.best_score_*-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the R2 scores still do poorly, either getting worse or improving a very small amount, but there is a more meaningful improvement in the error score, which noticeably degreases. As a result I am going to use `neg_root_mean_squared_error` as my scoring method during grid search. <p>\n",
    "Because `XGBRegressor` performs much better than `RandomForestRegressor`, I am going to only tune models for the feature selection sets on it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost best parameters for all features: \n",
      "For DC set:\n",
      " {'alpha': 0.1, 'lambda': 100, 'learning_rate': 0.3, 'max_depth': 6, 'n_estimators': 180}\n",
      "\n",
      "For London set:\n",
      " {'alpha': 0.75, 'lambda': 125, 'learning_rate': 0.3, 'max_depth': 7, 'n_estimators': 70}\n"
     ]
    }
   ],
   "source": [
    "print('XGBoost best parameters for all features: \\nFor DC set:\\n',result_boost_dc2.best_params_)\n",
    "print('\\nFor London set:\\n',result_boost_l2.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning on selected features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward/Backward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dc_fw = pd.read_pickle('../pickles/split/feat-select/forward/X_train_dc_fw.pkl')\n",
    "X_train_dc_bw = pd.read_pickle('../pickles/split/feat-select/backward/X_train_dc_bw.pkl')\n",
    "\n",
    "X_train_l_fwbw = pd.read_pickle('../pickles/split/feat-select/fwbw/X_train_l_fwbw.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost = XGBRegressor(objective='reg:squarederror',random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DC Set**<p>\n",
    "Forward Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_dc_fw = {\n",
    "    'alpha': [1,2,3],\n",
    "    'lambda': [40,50,60],\n",
    "    'max_depth': [5,6,7],\n",
    "    'learning_rate': [0.3,0.2,0.1],\n",
    "    'n_estimators': [360,370,380]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 56.837789313067205\n",
      "Best Hyperparameters: {'alpha': 2, 'lambda': 50, 'learning_rate': 0.2, 'max_depth': 6, 'n_estimators': 380}\n"
     ]
    }
   ],
   "source": [
    "search_dc_fw = GridSearchCV(boost, space_dc_fw, scoring='neg_root_mean_squared_error',n_jobs=-1)\n",
    "result_dc_fw = search_dc_fw.fit(X_train_dc_fw,y_train_dc)\n",
    "print('Best Score: %s' % (result_dc_fw.best_score_*-1))\n",
    "print('Best Hyperparameters: %s' % result_dc_fw.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backwards Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_dc_bw = {\n",
    "    'alpha': [0.6,0.7,0.8],\n",
    "    'lambda': [70,80,90],\n",
    "    'max_depth': [5,6,7],\n",
    "    'learning_rate': [0.3,0.2,0.1],\n",
    "    'n_estimators': [270,280,290]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 55.76142506506576\n",
      "Best Hyperparameters: {'alpha': 0.7, 'lambda': 80, 'learning_rate': 0.2, 'max_depth': 6, 'n_estimators': 280}\n"
     ]
    }
   ],
   "source": [
    "search_dc_bw = GridSearchCV(boost, space_dc_bw, scoring='neg_root_mean_squared_error',n_jobs=-1)\n",
    "result_dc_bw = search_dc_bw.fit(X_train_dc_bw,y_train_dc)\n",
    "print('Best Score: %s' % (result_dc_bw.best_score_*-1))\n",
    "print('Best Hyperparameters: %s' % result_dc_bw.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**London Set** <br>\n",
    "(This is forward *and* backward select.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_l_fwbw = {\n",
    "    'alpha': [0.001,0.01,0.1],\n",
    "    'lambda': [5,10,15],\n",
    "    'max_depth': [5,6,7],\n",
    "    'learning_rate': [0.2,0.1,0.01],\n",
    "    'n_estimators': [140,150,160]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 287.379267057117\n",
      "Best Hyperparameters: {'alpha': 0.01, 'lambda': 10, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 140}\n"
     ]
    }
   ],
   "source": [
    "search_l_fwbw = GridSearchCV(boost, space_l_fwbw, scoring='neg_root_mean_squared_error',n_jobs=-1)\n",
    "result_l_fwbw = search_l_fwbw.fit(X_train_l_fwbw,y_train_l)\n",
    "print('Best Score: %s' % (result_l_fwbw.best_score_*-1))\n",
    "print('Best Hyperparameters: %s' % result_l_fwbw.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dc_lasso = pd.read_pickle('../pickles/split/feat-select/lasso/X_train_dc_lasso.pkl')\n",
    "X_train_l_lasso = pd.read_pickle('../pickles/split/feat-select/lasso/X_train_l_lasso.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DC set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_dc_lasso = {\n",
    "    'alpha': [0.1,1,2],\n",
    "    'lambda': [120,130,140],\n",
    "    'max_depth': [5,6,7],\n",
    "    'learning_rate': [0.3,0.2,0.1],\n",
    "    'n_estimators': [180,190,200]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 60.833681953480436\n",
      "Best Hyperparameters: {'alpha': 1, 'lambda': 130, 'learning_rate': 0.2, 'max_depth': 6, 'n_estimators': 190}\n"
     ]
    }
   ],
   "source": [
    "search_dc_lasso = GridSearchCV(boost, space_dc_lasso, scoring='neg_root_mean_squared_error',n_jobs=-1)\n",
    "result_dc_lasso = search_dc_lasso.fit(X_train_dc_lasso,y_train_dc)\n",
    "print('Best Score: %s' % (result_dc_lasso.best_score_*-1))\n",
    "print('Best Hyperparameters: %s' % result_dc_lasso.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**London Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_l_lasso = {\n",
    "    'alpha': [0.1,0.01,0.001],\n",
    "    'lambda': [5,10,15],\n",
    "    'max_depth': [5,6,7],\n",
    "    'learning_rate': [0.2,0.1,0.01],\n",
    "    'n_estimators': [150,160,170]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 287.6278104393208\n",
      "Best Hyperparameters: {'alpha': 0.01, 'lambda': 10, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 160}\n"
     ]
    }
   ],
   "source": [
    "search_l_lasso = GridSearchCV(boost, space_l_lasso, scoring='neg_root_mean_squared_error',n_jobs=-1)\n",
    "result_l_lasso = search_l_lasso.fit(X_train_l_lasso,y_train_l)\n",
    "print('Best Score: %s' % (result_l_lasso.best_score_*-1))\n",
    "print('Best Hyperparameters: %s' % result_l_lasso.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put all of the results next to each other for easy comparisson. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost, rmse: \n",
      "DC set: \n",
      "  Base model: 69.92294989890084 \n",
      "  All features: 56.490411500995606 \n",
      "  Fw features: 56.837789313067205\n",
      "  Bw features: 55.76142506506576 \n",
      "  Lasso features: 60.833681953480436 \n",
      "\n",
      "London set: \n",
      "  Base model: 332.20786503370334\n",
      "  All features: 293.8955040541115 \n",
      "  FwBw features: 287.379267057117 \n",
      "  Lasso features: 287.6278104393208\n"
     ]
    }
   ],
   "source": [
    "print(f'XGBoost, rmse: \\nDC set: \\n  Base model: 69.92294989890084 \\n  All features: {(result_boost_dc2.best_score_*-1)} \\n  Fw features: {(result_dc_fw.best_score_*-1)}')\n",
    "print(f'  Bw features: {(result_dc_bw.best_score_*-1)} \\n  Lasso features: {(result_dc_lasso.best_score_*-1)} \\n\\nLondon set: \\n  Base model: 332.20786503370334')\n",
    "print(f'  All features: {(result_boost_l2.best_score_*-1)} \\n  FwBw features: {(result_l_fwbw.best_score_*-1)} \\n  Lasso features: {(result_l_lasso.best_score_*-1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both sets see a significant reduction in their error values; DC drops by about 20% and London by 13%. This is only on the training set, however, so I still need to run the entire model and see how it does, and see what variation of the features does the best, if there is even a significant difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to actaully run and do final evaluation of the models in another notebook for the sake of usability, so I need to print out the best parameters, to use in initiating models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dc allfeat params: {'alpha': 0.1, 'lambda': 100, 'learning_rate': 0.3, 'max_depth': 6, 'n_estimators': 180}\n",
      "lond allfeat params {'alpha': 0.75, 'lambda': 125, 'learning_rate': 0.3, 'max_depth': 7, 'n_estimators': 70}\n",
      "\n",
      "dc fw params: {'alpha': 2, 'lambda': 50, 'learning_rate': 0.2, 'max_depth': 6, 'n_estimators': 380}\n",
      "dc bw params: {'alpha': 0.7, 'lambda': 80, 'learning_rate': 0.2, 'max_depth': 6, 'n_estimators': 280}\n",
      "lond fwbw params: {'alpha': 0.01, 'lambda': 10, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 140}\n",
      "\n",
      "dc lasso params: {'alpha': 1, 'lambda': 130, 'learning_rate': 0.2, 'max_depth': 6, 'n_estimators': 190}\n",
      "lond lasso params: {'alpha': 0.01, 'lambda': 10, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 160}\n"
     ]
    }
   ],
   "source": [
    "print('dc allfeat params:',result_boost_dc2.best_params_)\n",
    "print('lond allfeat params',result_boost_l2.best_params_)\n",
    "print('\\ndc fw params:', result_dc_fw.best_params_)\n",
    "print('dc bw params:', result_dc_bw.best_params_)\n",
    "print('lond fwbw params:', result_l_fwbw.best_params_)\n",
    "print('\\ndc lasso params:', result_dc_lasso.best_params_)\n",
    "print('lond lasso params:', result_l_lasso.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
